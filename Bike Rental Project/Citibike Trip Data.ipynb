{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81fcd796",
   "metadata": {},
   "source": [
    "1. Let's import the modules we'll need to start off with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc7bf588",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import glob\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2dcef6",
   "metadata": {},
   "source": [
    "2. Now let's perform the following steps:\n",
    "    - Creata a variable **files**, where we'll *glob* together the dozen or so CSV files we have.\n",
    "    - Create an empty **df_list**, and then append each CSV file's data to it using a *for* loop\n",
    "    - Concatenate the **df_list** into a single dataframe **df**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77ec6bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(\"JC-2016**-citibike-tripdata.csv\")\n",
    "df_list = []\n",
    "\n",
    "for file in files:\n",
    "    data = pd.read_csv(file)\n",
    "    df_list.append(data)\n",
    "\n",
    "df = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdd203f",
   "metadata": {},
   "source": [
    "3. Let's check out the length of the data and then the first five rows of our **df** dataset to get an idea of what we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f941d0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247584\n",
      "<bound method NDFrame.head of        Trip Duration           Start Time            Stop Time  \\\n",
      "0                362  2016-01-01 00:02:52  2016-01-01 00:08:54   \n",
      "1                200  2016-01-01 00:18:22  2016-01-01 00:21:42   \n",
      "2                202  2016-01-01 00:18:25  2016-01-01 00:21:47   \n",
      "3                248  2016-01-01 00:23:13  2016-01-01 00:27:21   \n",
      "4                903  2016-01-01 01:03:20  2016-01-01 01:18:24   \n",
      "...              ...                  ...                  ...   \n",
      "15109            557  2016-12-31 23:10:16  2016-12-31 23:19:33   \n",
      "15110           2749  2016-12-31 23:29:39  2017-01-01 00:15:29   \n",
      "15111            173  2016-12-31 23:44:37  2016-12-31 23:47:31   \n",
      "15112           2424  2016-12-31 23:44:50  2017-01-01 00:25:14   \n",
      "15113           2419  2016-12-31 23:44:50  2017-01-01 00:25:10   \n",
      "\n",
      "       Start Station ID Start Station Name  Start Station Latitude  \\\n",
      "0                  3186      Grove St PATH               40.719586   \n",
      "1                  3186      Grove St PATH               40.719586   \n",
      "2                  3186      Grove St PATH               40.719586   \n",
      "3                  3209       Brunswick St               40.724176   \n",
      "4                  3195            Sip Ave               40.730743   \n",
      "...                 ...                ...                     ...   \n",
      "15109              3214   Essex Light Rail               40.712774   \n",
      "15110              3183     Exchange Place               40.716247   \n",
      "15111              3186      Grove St PATH               40.719586   \n",
      "15112              3214   Essex Light Rail               40.712774   \n",
      "15113              3214   Essex Light Rail               40.712774   \n",
      "\n",
      "       Start Station Longitude  End Station ID  End Station Name  \\\n",
      "0                   -74.043117            3209      Brunswick St   \n",
      "1                   -74.043117            3213    Van Vorst Park   \n",
      "2                   -74.043117            3213    Van Vorst Park   \n",
      "3                   -74.050656            3203     Hamilton Park   \n",
      "4                   -74.063784            3210    Pershing Field   \n",
      "...                        ...             ...               ...   \n",
      "15109               -74.036486            3203     Hamilton Park   \n",
      "15110               -74.033459            3183    Exchange Place   \n",
      "15111               -74.043117            3270   Jersey & 6th St   \n",
      "15112               -74.036486            3214  Essex Light Rail   \n",
      "15113               -74.036486            3214  Essex Light Rail   \n",
      "\n",
      "       End Station Latitude  End Station Longitude  Bike ID   User Type  \\\n",
      "0                 40.724176             -74.050656    24647  Subscriber   \n",
      "1                 40.718489             -74.047727    24605  Subscriber   \n",
      "2                 40.718489             -74.047727    24689  Subscriber   \n",
      "3                 40.727596             -74.044247    24693  Subscriber   \n",
      "4                 40.742677             -74.051789    24573    Customer   \n",
      "...                     ...                    ...      ...         ...   \n",
      "15109             40.727596             -74.044247    24465  Subscriber   \n",
      "15110             40.716247             -74.033459    24389    Customer   \n",
      "15111             40.725289             -74.045572    24641  Subscriber   \n",
      "15112             40.712774             -74.036486    26219  Subscriber   \n",
      "15113             40.712774             -74.036486    24471  Subscriber   \n",
      "\n",
      "       Birth Year  Gender  \n",
      "0          1964.0       2  \n",
      "1          1962.0       1  \n",
      "2          1962.0       2  \n",
      "3          1984.0       1  \n",
      "4             NaN       0  \n",
      "...           ...     ...  \n",
      "15109      1981.0       2  \n",
      "15110         NaN       0  \n",
      "15111      1978.0       1  \n",
      "15112      1960.0       2  \n",
      "15113      1956.0       1  \n",
      "\n",
      "[247584 rows x 15 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "print(df.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b7828b",
   "metadata": {},
   "source": [
    "4. Now let's start our data cleaning. First, let's see if, and how many of our 247,584 rows have null or missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75084cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trip Duration                  0\n",
      "Start Time                     0\n",
      "Stop Time                      0\n",
      "Start Station ID               0\n",
      "Start Station Name             0\n",
      "Start Station Latitude         0\n",
      "Start Station Longitude        0\n",
      "End Station ID                 0\n",
      "End Station Name               0\n",
      "End Station Latitude           0\n",
      "End Station Longitude          0\n",
      "Bike ID                        0\n",
      "User Type                    380\n",
      "Birth Year                 18999\n",
      "Gender                         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd3062c",
   "metadata": {},
   "source": [
    "5. Now, let's let **df** be our dataset with the missing or null data *drop*ped. Let's check that by printing the tally of rows with missing data again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a794e4e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trip Duration              0\n",
      "Start Time                 0\n",
      "Stop Time                  0\n",
      "Start Station ID           0\n",
      "Start Station Name         0\n",
      "Start Station Latitude     0\n",
      "Start Station Longitude    0\n",
      "End Station ID             0\n",
      "End Station Name           0\n",
      "End Station Latitude       0\n",
      "End Station Longitude      0\n",
      "Bike ID                    0\n",
      "User Type                  0\n",
      "Birth Year                 0\n",
      "Gender                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f939aca7",
   "metadata": {},
   "source": [
    "Indeed, no rows of missing or null data, which helps clean our data tremendously\n",
    "\n",
    "6. Let's see how many rows our dataset is now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d3e79d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228205\n"
     ]
    }
   ],
   "source": [
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0408f7fa",
   "metadata": {},
   "source": [
    "Our dataset is still quite large at 228,205 rows.\n",
    "\n",
    "7. Let's see what our column names are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1918870c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Trip Duration', 'Start Time', 'Stop Time', 'Start Station ID',\n",
      "       'Start Station Name', 'Start Station Latitude',\n",
      "       'Start Station Longitude', 'End Station ID', 'End Station Name',\n",
      "       'End Station Latitude', 'End Station Longitude', 'Bike ID', 'User Type',\n",
      "       'Birth Year', 'Gender'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d8ff69",
   "metadata": {},
   "source": [
    "8. Now, let's *describe* **df** to see if we can see any oddities or potential outliers in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f1a3588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Trip Duration  Start Station ID  Start Station Latitude  \\\n",
      "count   2.282050e+05     228205.000000           228205.000000   \n",
      "mean    7.423686e+02       3207.201240               40.723299   \n",
      "std     3.699906e+04         27.004405                0.008149   \n",
      "min     6.100000e+01       3183.000000               40.692640   \n",
      "25%     2.420000e+02       3186.000000               40.717732   \n",
      "50%     3.700000e+02       3202.000000               40.721525   \n",
      "75%     6.110000e+02       3211.000000               40.727596   \n",
      "max     1.632981e+07       3426.000000               40.752559   \n",
      "\n",
      "       Start Station Longitude  End Station ID  End Station Latitude  \\\n",
      "count            228205.000000   228205.000000         228205.000000   \n",
      "mean                -74.046623     3203.900107             40.722738   \n",
      "std                   0.011176       55.399628              0.007904   \n",
      "min                 -74.096937      173.000000             40.692216   \n",
      "25%                 -74.050656     3186.000000             40.717732   \n",
      "50%                 -74.044247     3198.000000             40.721124   \n",
      "75%                 -74.038051     3211.000000             40.727596   \n",
      "max                 -74.032108     3426.000000             40.801343   \n",
      "\n",
      "       End Station Longitude        Bike ID     Birth Year         Gender  \n",
      "count          228205.000000  228205.000000  228205.000000  228205.000000  \n",
      "mean              -74.046027   24938.675458    1979.328547       1.216761  \n",
      "std                 0.011254     749.938286       9.595552       0.421523  \n",
      "min               -74.096937   14552.000000    1900.000000       0.000000  \n",
      "25%               -74.050656   24491.000000    1974.000000       1.000000  \n",
      "50%               -74.043845   24612.000000    1981.000000       1.000000  \n",
      "75%               -74.038051   24719.000000    1986.000000       1.000000  \n",
      "max               -73.957390   27274.000000    2000.000000       2.000000  \n"
     ]
    }
   ],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1260f9ed",
   "metadata": {},
   "source": [
    "Several things stick out at first glance that we'll want to investigate further:\n",
    "1. There is a minimum Birth Year of 1900. While it is technically possible to have a 116-year-old person still living, it's quite unlikely for someone that old still be able to ride a bicycle.\n",
    "2. There is quite a long maximum trip duration, over 16.32981 million seconds, which would equate to approximately 272,163 minutes, or about 4,536 hours, or about 189 days. That seems like one long bike trip!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184e951e",
   "metadata": {},
   "source": [
    "8. Let's investigate this apparent Birth Year anomaly. Let's print out the unique Birth Year values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04a9be39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1964. 1962. 1984. 1988. 1980. 1990. 1993. 1976. 1992. 1991. 1968. 1975.\n",
      " 1982. 1981. 1986. 1966. 1972. 1977. 1979. 1987. 1983. 1957. 1956. 1960.\n",
      " 1985. 1969. 1989. 1950. 1978. 1961. 1996. 1970. 1974. 1971. 1973. 1965.\n",
      " 1963. 1994. 1949. 1955. 1967. 1951. 1959. 1954. 1953. 1958. 1944. 1941.\n",
      " 1995. 1998. 1952. 1945. 1947. 1948. 1999. 1997. 1946. 1943. 2000. 1940.\n",
      " 1934. 1942. 1937. 1900.]\n"
     ]
    }
   ],
   "source": [
    "print(df['Birth Year'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117693d4",
   "metadata": {},
   "source": [
    "9. It looks like there may not be a birth year prior to the 1930s decade, except for 1900, but let's narrow down this list to birth years to 1950 and before to get a closer look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "455149ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1950. 1949. 1944. 1941. 1945. 1947. 1948. 1946. 1943. 1940. 1934. 1942.\n",
      " 1937. 1900.]\n"
     ]
    }
   ],
   "source": [
    "print(df['Birth Year'][df['Birth Year'] <= 1950].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2d2036",
   "metadata": {},
   "source": [
    "Confirmed. 1900 is the only pre-1930s birth year, so we'll consider this an outlier. Most likely someone made a typo when purchasing a pass.\n",
    "\n",
    "10. Let's drop this outlier by letting our **df** be equal to any rows with Birth Year being greater than or equal to 1930. Let's also confirm no 1900 birth year remains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34fdf7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1950. 1949. 1944. 1941. 1945. 1947. 1948. 1946. 1943. 1940. 1934. 1942.\n",
      " 1937.]\n"
     ]
    }
   ],
   "source": [
    "df = df[df['Birth Year'] >= 1930]\n",
    "print(df['Birth Year'][df['Birth Year'] <= 1950].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1093c5aa",
   "metadata": {},
   "source": [
    "11. Now let's investigate the apparent outlier of the Trip Duration column. First let's check out the mininum, maximum, and median values of Trip Duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "316f2078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n",
      "16329808\n",
      "370.0\n"
     ]
    }
   ],
   "source": [
    "print(df['Trip Duration'].min())\n",
    "print(df['Trip Duration'].max())\n",
    "print(df['Trip Duration'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92a82b8",
   "metadata": {},
   "source": [
    "It seems that the 61-second minimum, and 370-second median make this 16,329,808-second maximum all that much more of an outlier. \n",
    "\n",
    "12. Let's print any rows that have a Trip Duration more than 1 million seconds to see if there are any other trip durations that are similarly outlying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5199886a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Trip Duration           Start Time            Stop Time  \\\n",
      "3233         2104123  2016-02-12 07:27:56  2016-03-07 15:56:40   \n",
      "3269         2100551  2016-02-12 08:31:06  2016-03-07 16:00:18   \n",
      "3371         2071209  2016-02-12 16:32:54  2016-03-07 15:53:03   \n",
      "8903        16329808  2016-03-22 07:02:10  2016-09-27 07:05:38   \n",
      "14746        1837255  2016-04-28 09:05:14  2016-05-19 15:26:09   \n",
      "2894         1120971  2016-09-03 22:05:27  2016-09-16 21:28:18   \n",
      "11356        1532001  2016-09-11 16:32:21  2016-09-29 10:05:42   \n",
      "18510        4826890  2016-11-23 17:38:36  2017-01-18 14:26:46   \n",
      "\n",
      "       Start Station ID    Start Station Name  Start Station Latitude  \\\n",
      "3233               3214      Essex Light Rail               40.712774   \n",
      "3269               3184           Paulus Hook               40.714145   \n",
      "3371               3183        Exchange Place               40.716247   \n",
      "8903               3215           Central Ave               40.746730   \n",
      "14746              3192    Liberty Light Rail               40.711242   \n",
      "2894               3189  West Side Light Rail               40.714402   \n",
      "11356              3197              North St               40.752559   \n",
      "18510              3280           Astor Place               40.719282   \n",
      "\n",
      "       Start Station Longitude  End Station ID      End Station Name  \\\n",
      "3233                -74.036486            3183        Exchange Place   \n",
      "3269                -74.033552            3183        Exchange Place   \n",
      "3371                -74.033459            3183        Exchange Place   \n",
      "8903                -74.049251            3267          Morris Canal   \n",
      "14746               -74.055701            3183        Exchange Place   \n",
      "2894                -74.088772            3189  West Side Light Rail   \n",
      "11356               -74.044725            3210        Pershing Field   \n",
      "18510               -74.071262            3426            JCBS Depot   \n",
      "\n",
      "       End Station Latitude  End Station Longitude  Bike ID   User Type  \\\n",
      "3233              40.716247             -74.033459    24555  Subscriber   \n",
      "3269              40.716247             -74.033459    24720  Subscriber   \n",
      "3371              40.716247             -74.033459    24664  Subscriber   \n",
      "8903              40.712419             -74.038526    24519  Subscriber   \n",
      "14746             40.716247             -74.033459    24515  Subscriber   \n",
      "2894              40.714402             -74.088772    24556  Subscriber   \n",
      "11356             40.742677             -74.051789    24522  Subscriber   \n",
      "18510             40.709651             -74.068601    24711  Subscriber   \n",
      "\n",
      "       Birth Year  Gender  \n",
      "3233       1968.0       1  \n",
      "3269       1970.0       1  \n",
      "3371       1988.0       2  \n",
      "8903       1975.0       1  \n",
      "14746      1964.0       1  \n",
      "2894       1970.0       1  \n",
      "11356      1991.0       1  \n",
      "18510      1989.0       1  \n"
     ]
    }
   ],
   "source": [
    "print(df[df['Trip Duration'] > 1000000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9794c5fd",
   "metadata": {},
   "source": [
    "It looks like there are several other Trip Durations greater than 1 million seconds, including one with over 4.8 million seconds. It's also interesting to note that all of these Trip Durations are \"Subscriber\" User Types. In looking at the accompanying documentation provided, these \"Subscriber\"s have annual memberships. One whole year is 31,536,000 seconds, so these apparent outlyers are actually sensible. This data is not dirty as first thought, so we'll leave this data alone."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c023cfa",
   "metadata": {},
   "source": [
    "Now let's shift gears and think about how we want to break our data up so that we can create a database schema for a PostGreSQL database. When looking at the columns earlier, it appears that there are multiple columns related to the stations, such as latitude, longitude, ID, and Name. This seems like the perfect candidate to break off into its own database.\n",
    "\n",
    "13. First, let's identify which stations are used to start a bike trip while retaining that station's information. We'll subset this information into a new **start_stations** dataframe. We'll want to drop duplicates since we want a list of unique stations. While we're at it, let's rename the columns to make it easier to use later in our future database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f256ea5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       station_id             station_name  station_lat  station_long\n",
      "0            3186            Grove St PATH    40.719586    -74.043117\n",
      "3            3209             Brunswick St    40.724176    -74.050656\n",
      "7            3211               Newark Ave    40.721525    -74.046305\n",
      "8            3187                Warren St    40.721124    -74.038051\n",
      "10           3183           Exchange Place    40.716247    -74.033459\n",
      "11           3213           Van Vorst Park    40.718489    -74.047727\n",
      "14           3193             Lincoln Park    40.724605    -74.078406\n",
      "19           3194          McGinley Square    40.725340    -74.067622\n",
      "20           3202             Newport PATH    40.727224    -74.033759\n",
      "23           3196           Riverview Park    40.744319    -74.043991\n",
      "27           3214         Essex Light Rail    40.712774    -74.036486\n",
      "28           3195                  Sip Ave    40.730743    -74.063784\n",
      "33           3207              Oakland Ave    40.737604    -74.052478\n",
      "37           3199             Newport Pkwy    40.728745    -74.032108\n",
      "40           3203            Hamilton Park    40.727596    -74.044247\n",
      "41           3210           Pershing Field    40.742677    -74.051789\n",
      "42           3190     Garfield Ave Station    40.710467    -74.070039\n",
      "48           3185                City Hall    40.717732    -74.043845\n",
      "55           3197                 North St    40.752559    -74.044725\n",
      "62           3212          Christ Hospital    40.734786    -74.050444\n",
      "65           3225    Baldwin at Montgomery    40.723659    -74.064194\n",
      "71           3192       Liberty Light Rail    40.711242    -74.055701\n",
      "73           3215              Central Ave    40.746730    -74.049251\n",
      "101          3206                  Hilltop    40.731169    -74.057574\n",
      "117          3184              Paulus Hook    40.714145    -74.033552\n",
      "119          3205        JC Medical Center    40.716540    -74.049638\n",
      "124          3198         Heights Elevator    40.748716    -74.040443\n",
      "132          3220        5 Corners Library    40.734961    -74.059503\n",
      "201          3191                 Union St    40.718211    -74.083639\n",
      "203          3201                   Dey St    40.737711    -74.066921\n",
      "1033         3188                     NJCU    40.710109    -74.085849\n",
      "2843         3200           MLK Light Rail    40.711131    -74.078885\n",
      "4429         3216            Columbia Park    40.697030    -74.096937\n",
      "5441         3189     West Side Light Rail    40.714402    -74.088772\n",
      "5064         3217             Bayside Park    40.698651    -74.082080\n",
      "15283        3267             Morris Canal    40.712419    -74.038526\n",
      "15362        3270          Jersey & 6th St    40.725289    -74.045572\n",
      "16965        3272             Jersey & 3rd    40.723332    -74.045953\n",
      "17111        3268           Lafayette Park    40.713464    -74.062859\n",
      "20522        3278         Monmouth and 6th    40.725685    -74.048790\n",
      "20753        3279              Dixon Mills    40.721630    -74.049968\n",
      "22249        3276         Marin Light Rail    40.714584    -74.042817\n",
      "22381        3273             Manila & 1st    40.721651    -74.042884\n",
      "22735        3275           Columbus Drive    40.718355    -74.038914\n",
      "22926        3274           Bethune Center    40.704958    -74.085931\n",
      "23085        3281      Leonard Gordon Park    40.745910    -74.057271\n",
      "23397        3271      Danforth Light Rail    40.692640    -74.088012\n",
      "26638        3269          Brunswick & 6th    40.726012    -74.050389\n",
      "27614        3280              Astor Place    40.719282    -74.071262\n",
      "573          3426               JCBS Depot    40.709651    -74.068601\n",
      "11530        3277  Communipaw & Berry Lane    40.714358    -74.066611\n"
     ]
    }
   ],
   "source": [
    "start_stations = df[['Start Station ID', 'Start Station Name', 'Start Station Latitude', 'Start Station Longitude']]\n",
    "# print(start_stations)\n",
    "start_stations = start_stations.drop_duplicates()\n",
    "start_stations = start_stations.rename(columns={'Start Station ID':'station_id', 'Start Station Name': 'station_name', 'Start Station Latitude': 'station_lat', 'Start Station Longitude':'station_long'})\n",
    "print(start_stations)\n",
    "# print(len(start_stations))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e39534c",
   "metadata": {},
   "source": [
    "14. Let's repeat these exact steps for our end station data for an **end_stations**. Let's use the exact same column names as  **start_stations** so that we can concatenate these two dataframes together in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad4d0616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      station_id                   station_name  station_lat  station_long\n",
      "0           3209                   Brunswick St    40.724176    -74.050656\n",
      "1           3213                 Van Vorst Park    40.718489    -74.047727\n",
      "3           3203                  Hamilton Park    40.727596    -74.044247\n",
      "8           3214               Essex Light Rail    40.712774    -74.036486\n",
      "10          3187                      Warren St    40.721124    -74.038051\n",
      "...          ...                            ...          ...           ...\n",
      "1400        2004              6 Ave & Broome St    40.724399    -74.004704\n",
      "5142         393              E 5 St & Avenue C    40.722992    -73.979955\n",
      "9792        3277        Communipaw & Berry Lane    40.714358    -74.066611\n",
      "245          405  Washington St & Gansevoort St    40.739323    -74.008119\n",
      "5488         224          Spruce St & Nassau St    40.711464    -74.005524\n",
      "\n",
      "[90 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "end_stations = df[['End Station ID', 'End Station Name', 'End Station Latitude', 'End Station Longitude']]\n",
    "# print(end_stations)\n",
    "end_stations = end_stations.drop_duplicates()\n",
    "end_stations = end_stations.rename(columns={'End Station ID':'station_id', 'End Station Name': 'station_name', 'End Station Latitude': 'station_lat', 'End Station Longitude':'station_long'})\n",
    "print(end_stations)\n",
    "# print(len(end_stations))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7e1caf",
   "metadata": {},
   "source": [
    "15. Now let's concatenate these dataframes into one **all_stations** dataframe. Then let's sort them into numerical order by station_id, and then let's drop any duplicate stations since we want unique stations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c10c155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       station_id                  station_name  station_lat  station_long\n",
      "7642          173            Broadway & W 49 St    40.760683    -73.984527\n",
      "5488          224         Spruce St & Nassau St    40.711464    -74.005524\n",
      "5439          225       W 14 St & The High Line    40.741951    -74.008030\n",
      "1188          249       Harrison St & Hudson St    40.718710    -74.009001\n",
      "7822          252  MacDougal St & Washington Sq    40.732264    -73.998522\n",
      "...           ...                           ...          ...           ...\n",
      "27614        3280                   Astor Place    40.719282    -74.071262\n",
      "23085        3281           Leonard Gordon Park    40.745910    -74.057271\n",
      "6194         3314            W 95 St & Broadway    40.793770    -73.971888\n",
      "22692        3331       Riverside Dr & W 104 St    40.801343    -73.971146\n",
      "573          3426                    JCBS Depot    40.709651    -74.068601\n",
      "\n",
      "[90 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "all_stations = pd.concat([start_stations, end_stations])\n",
    "all_stations = all_stations.sort_values(by='station_id')\n",
    "all_stations = all_stations.drop_duplicates()\n",
    "print(all_stations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5cb57a",
   "metadata": {},
   "source": [
    "16. Now let's clean up the **df** dataframe by eliminating the station information, except for the Start Station ID and End Station ID columns. In our upcoming database, we can perform joins using these columns to pull all the station information we need from our newly created **all_stations** dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c6c1948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Trip Duration           Start Time            Stop Time  Start Station ID  \\\n",
      "0            362  2016-01-01 00:02:52  2016-01-01 00:08:54              3186   \n",
      "1            200  2016-01-01 00:18:22  2016-01-01 00:21:42              3186   \n",
      "2            202  2016-01-01 00:18:25  2016-01-01 00:21:47              3186   \n",
      "3            248  2016-01-01 00:23:13  2016-01-01 00:27:21              3209   \n",
      "6            445  2016-01-01 01:07:45  2016-01-01 01:15:11              3186   \n",
      "\n",
      "   End Station ID  Bike ID   User Type  Birth Year  Gender  \n",
      "0            3209    24647  Subscriber      1964.0       2  \n",
      "1            3213    24605  Subscriber      1962.0       1  \n",
      "2            3213    24689  Subscriber      1962.0       2  \n",
      "3            3203    24693  Subscriber      1984.0       1  \n",
      "6            3203    24510  Subscriber      1988.0       2  \n"
     ]
    }
   ],
   "source": [
    "df = df[['Trip Duration', 'Start Time', 'Stop Time', 'Start Station ID', 'End Station ID', 'Bike ID', 'User Type',\n",
    "       'Birth Year', 'Gender']]\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9aceba2",
   "metadata": {},
   "source": [
    "17. Next, let's rename the **df** columns so that they will be easier to work with in our upcoming database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8ae4ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   trip_duration_sec           start_time            stop_time  \\\n",
      "0                362  2016-01-01 00:02:52  2016-01-01 00:08:54   \n",
      "1                200  2016-01-01 00:18:22  2016-01-01 00:21:42   \n",
      "2                202  2016-01-01 00:18:25  2016-01-01 00:21:47   \n",
      "3                248  2016-01-01 00:23:13  2016-01-01 00:27:21   \n",
      "6                445  2016-01-01 01:07:45  2016-01-01 01:15:11   \n",
      "\n",
      "   start_station_id  end_station_id  bike_id   user_type  birth_year  gender  \n",
      "0              3186            3209    24647  Subscriber      1964.0       2  \n",
      "1              3186            3213    24605  Subscriber      1962.0       1  \n",
      "2              3186            3213    24689  Subscriber      1962.0       2  \n",
      "3              3209            3203    24693  Subscriber      1984.0       1  \n",
      "6              3186            3203    24510  Subscriber      1988.0       2  \n"
     ]
    }
   ],
   "source": [
    "df = df.rename(columns={'Trip Duration':'trip_duration_sec', 'Start Time':'start_time', 'Stop Time':'stop_time', \n",
    "                        'Start Station ID':'start_station_id', 'End Station ID':'end_station_id', 'Bike ID':'bike_id',\n",
    "                        'User Type':'user_type','Birth Year':'birth_year', 'Gender':'gender'})\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33927c52",
   "metadata": {},
   "source": [
    "18. Now, let's print the data type of each column to see if the data types are as expected. First with **df**, then with the **all_stations** dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2006d6bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trip_duration_sec      int64\n",
      "start_time            object\n",
      "stop_time             object\n",
      "start_station_id       int64\n",
      "end_station_id         int64\n",
      "bike_id                int64\n",
      "user_type             object\n",
      "birth_year           float64\n",
      "gender                 int64\n",
      "dtype: object\n",
      "station_id        int64\n",
      "station_name     object\n",
      "station_lat     float64\n",
      "station_long    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)\n",
    "print(all_stations.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5956dfd",
   "metadata": {},
   "source": [
    "19. Let's replace the numbers in the gender column as follows:\n",
    "- 2: Female\n",
    "- 1: Male\n",
    "- 0: Unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9950bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.gender = df.gender.replace(2, 'Female')\n",
    "df.gender = df.gender.replace(1, 'Male')\n",
    "df.gender = df.gender.replace(0, 'Unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fa277c",
   "metadata": {},
   "source": [
    "19. Let's change the birth_year to the 'int64' data type. We only need this column to be in whole numbers, or integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70775443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trip_duration_sec     int64\n",
      "start_time           object\n",
      "stop_time            object\n",
      "start_station_id      int64\n",
      "end_station_id        int64\n",
      "bike_id               int64\n",
      "user_type            object\n",
      "birth_year            int64\n",
      "gender               object\n",
      "dtype: object\n",
      "   trip_duration_sec           start_time            stop_time  \\\n",
      "0                362  2016-01-01 00:02:52  2016-01-01 00:08:54   \n",
      "1                200  2016-01-01 00:18:22  2016-01-01 00:21:42   \n",
      "2                202  2016-01-01 00:18:25  2016-01-01 00:21:47   \n",
      "3                248  2016-01-01 00:23:13  2016-01-01 00:27:21   \n",
      "6                445  2016-01-01 01:07:45  2016-01-01 01:15:11   \n",
      "\n",
      "   start_station_id  end_station_id  bike_id   user_type  birth_year  gender  \n",
      "0              3186            3209    24647  Subscriber        1964  Female  \n",
      "1              3186            3213    24605  Subscriber        1962    Male  \n",
      "2              3186            3213    24689  Subscriber        1962  Female  \n",
      "3              3209            3203    24693  Subscriber        1984    Male  \n",
      "6              3186            3203    24510  Subscriber        1988  Female  \n"
     ]
    }
   ],
   "source": [
    "df.birth_year = df.birth_year.astype('int64')\n",
    "print(df.dtypes)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcc32d0",
   "metadata": {},
   "source": [
    "20. Let's parse out the date only in both the start_time and stop_time columns into new columns start_date and stop_date, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ea6cd34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trip_duration_sec     int64\n",
      "start_time           object\n",
      "stop_time            object\n",
      "start_station_id      int64\n",
      "end_station_id        int64\n",
      "bike_id               int64\n",
      "user_type            object\n",
      "birth_year            int64\n",
      "gender               object\n",
      "start_date           object\n",
      "end_date             object\n",
      "dtype: object\n",
      "   trip_duration_sec           start_time            stop_time  \\\n",
      "0                362  2016-01-01 00:02:52  2016-01-01 00:08:54   \n",
      "1                200  2016-01-01 00:18:22  2016-01-01 00:21:42   \n",
      "2                202  2016-01-01 00:18:25  2016-01-01 00:21:47   \n",
      "3                248  2016-01-01 00:23:13  2016-01-01 00:27:21   \n",
      "6                445  2016-01-01 01:07:45  2016-01-01 01:15:11   \n",
      "\n",
      "   start_station_id  end_station_id  bike_id   user_type  birth_year  gender  \\\n",
      "0              3186            3209    24647  Subscriber        1964  Female   \n",
      "1              3186            3213    24605  Subscriber        1962    Male   \n",
      "2              3186            3213    24689  Subscriber        1962  Female   \n",
      "3              3209            3203    24693  Subscriber        1984    Male   \n",
      "6              3186            3203    24510  Subscriber        1988  Female   \n",
      "\n",
      "   start_date    end_date  \n",
      "0  2016-01-01  2016-01-01  \n",
      "1  2016-01-01  2016-01-01  \n",
      "2  2016-01-01  2016-01-01  \n",
      "3  2016-01-01  2016-01-01  \n",
      "6  2016-01-01  2016-01-01  \n"
     ]
    }
   ],
   "source": [
    "df['start_date'] = pd.to_datetime(df['start_time']).dt.date\n",
    "df['end_date'] = pd.to_datetime(df['stop_time']).dt.date\n",
    "print(df.dtypes)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ec2bbd",
   "metadata": {},
   "source": [
    "20. Now that we have our start_date and stop_date, let's *drop* the start_time and stop_time columns and place the start_date and end_date in their place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e7281b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   trip_duration_sec  start_date    end_date  start_station_id  \\\n",
      "0                362  2016-01-01  2016-01-01              3186   \n",
      "1                200  2016-01-01  2016-01-01              3186   \n",
      "2                202  2016-01-01  2016-01-01              3186   \n",
      "3                248  2016-01-01  2016-01-01              3209   \n",
      "6                445  2016-01-01  2016-01-01              3186   \n",
      "\n",
      "   end_station_id  bike_id   user_type  birth_year  gender  \n",
      "0            3209    24647  Subscriber        1964  Female  \n",
      "1            3213    24605  Subscriber        1962    Male  \n",
      "2            3213    24689  Subscriber        1962  Female  \n",
      "3            3203    24693  Subscriber        1984    Male  \n",
      "6            3203    24510  Subscriber        1988  Female  \n",
      "trip_duration_sec     int64\n",
      "start_date           object\n",
      "end_date             object\n",
      "start_station_id      int64\n",
      "end_station_id        int64\n",
      "bike_id               int64\n",
      "user_type            object\n",
      "birth_year            int64\n",
      "gender               object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df = df[['trip_duration_sec', 'start_date', 'end_date', 'start_station_id', 'end_station_id', 'bike_id', 'user_type',\n",
    "        'birth_year', 'gender']]\n",
    "print(df.head())\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654bacbf",
   "metadata": {},
   "source": [
    "21. Now both our datasets are clean enough for the database we will create. Let's write these to CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a9e4bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('trip_data.csv', index=False)\n",
    "all_stations.to_csv('stations.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
