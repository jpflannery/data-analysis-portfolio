{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81fcd796",
   "metadata": {},
   "source": [
    "1. Let's import the modules we'll need to start off with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc7bf588",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2dcef6",
   "metadata": {},
   "source": [
    "2. Now let's import the **newark_airport_2016.csv** data into a new dataframe **newark**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77ec6bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "newark = pd.read_csv('newark_airport_2016.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdd203f",
   "metadata": {},
   "source": [
    "3. Let's check out the length of the data and then the first five rows of our **newark** dataset to get an idea of what we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f941d0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "366\n",
      "<bound method NDFrame.head of          STATION                                         NAME        DATE  \\\n",
      "0    USW00014734  NEWARK LIBERTY INTERNATIONAL AIRPORT, NJ US  2016-01-01   \n",
      "1    USW00014734  NEWARK LIBERTY INTERNATIONAL AIRPORT, NJ US  2016-01-02   \n",
      "2    USW00014734  NEWARK LIBERTY INTERNATIONAL AIRPORT, NJ US  2016-01-03   \n",
      "3    USW00014734  NEWARK LIBERTY INTERNATIONAL AIRPORT, NJ US  2016-01-04   \n",
      "4    USW00014734  NEWARK LIBERTY INTERNATIONAL AIRPORT, NJ US  2016-01-05   \n",
      "..           ...                                          ...         ...   \n",
      "361  USW00014734  NEWARK LIBERTY INTERNATIONAL AIRPORT, NJ US  2016-12-27   \n",
      "362  USW00014734  NEWARK LIBERTY INTERNATIONAL AIRPORT, NJ US  2016-12-28   \n",
      "363  USW00014734  NEWARK LIBERTY INTERNATIONAL AIRPORT, NJ US  2016-12-29   \n",
      "364  USW00014734  NEWARK LIBERTY INTERNATIONAL AIRPORT, NJ US  2016-12-30   \n",
      "365  USW00014734  NEWARK LIBERTY INTERNATIONAL AIRPORT, NJ US  2016-12-31   \n",
      "\n",
      "      AWND  PGTM  PRCP  SNOW  SNWD  TAVG  TMAX  TMIN  TSUN  WDF2   WDF5  WSF2  \\\n",
      "0    12.75   NaN  0.00   0.0   0.0    41    43    34   NaN   270  280.0  25.9   \n",
      "1     9.40   NaN  0.00   0.0   0.0    36    42    30   NaN   260  260.0  21.0   \n",
      "2    10.29   NaN  0.00   0.0   0.0    37    47    28   NaN   270  250.0  23.9   \n",
      "3    17.22   NaN  0.00   0.0   0.0    32    35    14   NaN   330  330.0  25.9   \n",
      "4     9.84   NaN  0.00   0.0   0.0    19    31    10   NaN   360  350.0  25.1   \n",
      "..     ...   ...   ...   ...   ...   ...   ...   ...   ...   ...    ...   ...   \n",
      "361  13.65   NaN  0.01   0.0   0.0    53    62    40   NaN   270  270.0  29.1   \n",
      "362   8.28   NaN  0.00   0.0   0.0    41    43    31   NaN   330  330.0  19.9   \n",
      "363   8.05   NaN  0.36   0.0   0.0    38    45    31   NaN   170  150.0  18.1   \n",
      "364  14.99   NaN  0.00   0.0   0.0    37    42    32   NaN   270  270.0  25.9   \n",
      "365  12.30   NaN  0.00   0.0   0.0    35    44    29   NaN   200  220.0  21.9   \n",
      "\n",
      "     WSF5  \n",
      "0    35.1  \n",
      "1    25.1  \n",
      "2    30.0  \n",
      "3    33.1  \n",
      "4    31.1  \n",
      "..    ...  \n",
      "361  38.0  \n",
      "362  25.1  \n",
      "363  25.1  \n",
      "364  33.1  \n",
      "365  28.0  \n",
      "\n",
      "[366 rows x 16 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(len(newark))\n",
    "print(newark.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b7828b",
   "metadata": {},
   "source": [
    "It looks like one row for each of the 366 days of the year 2016\n",
    "\n",
    "4. Now let's start our data cleaning. First, let's see if, and how many of our 366 rows have null or missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75084cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATION      0\n",
      "NAME         0\n",
      "DATE         0\n",
      "AWND         0\n",
      "PGTM       366\n",
      "PRCP         0\n",
      "SNOW         0\n",
      "SNWD         0\n",
      "TAVG         0\n",
      "TMAX         0\n",
      "TMIN         0\n",
      "TSUN       366\n",
      "WDF2         0\n",
      "WDF5         2\n",
      "WSF2         0\n",
      "WSF5         2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(newark.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd3062c",
   "metadata": {},
   "source": [
    "5. Now, let's let **newark** be our dataset with the missing or null data *drop*ped. However, we don't want to eliminate any rows since all rows contain valuable weather observation data. Instead, we will drop the PGTM and TSUN columns since they are empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a794e4e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATION    0\n",
      "NAME       0\n",
      "DATE       0\n",
      "AWND       0\n",
      "PRCP       0\n",
      "SNOW       0\n",
      "SNWD       0\n",
      "TAVG       0\n",
      "TMAX       0\n",
      "TMIN       0\n",
      "WDF2       0\n",
      "WDF5       2\n",
      "WSF2       0\n",
      "WSF5       2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "newark = newark.drop(['PGTM', 'TSUN'], axis=1)\n",
    "print(newark.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f939aca7",
   "metadata": {},
   "source": [
    "Looks like, after that is done, we still have some missing or null data in the WDF5 and WSF5 columns.\n",
    "\n",
    "6. Let's print and rows where either column is missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d3e79d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         STATION                                         NAME        DATE  \\\n",
      "32   USW00014734  NEWARK LIBERTY INTERNATIONAL AIRPORT, NJ US  2016-02-02   \n",
      "329  USW00014734  NEWARK LIBERTY INTERNATIONAL AIRPORT, NJ US  2016-11-25   \n",
      "\n",
      "     AWND  PRCP  SNOW  SNWD  TAVG  TMAX  TMIN  WDF2  WDF5  WSF2  WSF5  \n",
      "32    3.8  0.00   0.0   1.2    43    51    32   350   NaN  11.0   NaN  \n",
      "329   4.7  0.01   0.0   0.0    48    55    45   220   NaN   8.1   NaN  \n"
     ]
    }
   ],
   "source": [
    "print(newark[newark.WDF5.isna() | newark.WSF5.isna()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0408f7fa",
   "metadata": {},
   "source": [
    "We'll address those missing values in a few steps, but let's look at our column names. They don't appear to be very descriptive or helpful to us, so we should consider changing them.\n",
    "\n",
    "7. Let's see what our column names are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1918870c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['STATION', 'NAME', 'DATE', 'AWND', 'PRCP', 'SNOW', 'SNWD', 'TAVG',\n",
      "       'TMAX', 'TMIN', 'WDF2', 'WDF5', 'WSF2', 'WSF5'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(newark.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1177e9",
   "metadata": {},
   "source": [
    "8. Next, let's rename the **newark** columns so that A. they will be easier to understand, and B. they will be easier to work with in our upcoming database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8ae4ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       station                                         name        date  \\\n",
      "0  USW00014734  NEWARK LIBERTY INTERNATIONAL AIRPORT, NJ US  2016-01-01   \n",
      "1  USW00014734  NEWARK LIBERTY INTERNATIONAL AIRPORT, NJ US  2016-01-02   \n",
      "2  USW00014734  NEWARK LIBERTY INTERNATIONAL AIRPORT, NJ US  2016-01-03   \n",
      "3  USW00014734  NEWARK LIBERTY INTERNATIONAL AIRPORT, NJ US  2016-01-04   \n",
      "4  USW00014734  NEWARK LIBERTY INTERNATIONAL AIRPORT, NJ US  2016-01-05   \n",
      "\n",
      "   avg_daily_wind_mph  precip_in  snow_accum_in  snow_depth_in  avg_temp_f  \\\n",
      "0               12.75        0.0            0.0            0.0          41   \n",
      "1                9.40        0.0            0.0            0.0          36   \n",
      "2               10.29        0.0            0.0            0.0          37   \n",
      "3               17.22        0.0            0.0            0.0          32   \n",
      "4                9.84        0.0            0.0            0.0          19   \n",
      "\n",
      "   max_temp_f  min_temp_f  avg_2sec_wind_dir  avg_5sec_wind_dir  \\\n",
      "0          43          34                270              280.0   \n",
      "1          42          30                260              260.0   \n",
      "2          47          28                270              250.0   \n",
      "3          35          14                330              330.0   \n",
      "4          31          10                360              350.0   \n",
      "\n",
      "   max_2sec_wind_mph  max_5sec_wind_mph  \n",
      "0               25.9               35.1  \n",
      "1               21.0               25.1  \n",
      "2               23.9               30.0  \n",
      "3               25.9               33.1  \n",
      "4               25.1               31.1  \n"
     ]
    }
   ],
   "source": [
    "newark = newark.rename(columns={'STATION':'station', 'NAME':'name', 'DATE':'date', 'AWND':'avg_daily_wind_mph',\n",
    "                        'PRCP':'precip_in', 'SNOW':'snow_accum_in', 'SNWD':'snow_depth_in','TAVG':'avg_temp_f',\n",
    "                        'TMAX':'max_temp_f', 'TMIN':'min_temp_f', 'WDF2':'avg_2sec_wind_dir', 'WDF5':'avg_5sec_wind_dir',\n",
    "                        'WSF2':'max_2sec_wind_mph', 'WSF5':'max_5sec_wind_mph'})\n",
    "print(newark.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f73085",
   "metadata": {},
   "source": [
    "Come to think of it, there are still some columns left that are not really of any use to us here:\n",
    "- station\n",
    "- avg_2sec_wind_dir\n",
    "- avg_5sec_wind_dir\n",
    "- max_2sec_wind_mph\n",
    "- max_5sec_wind_mph\n",
    "\n",
    "9. Let's *drop* these columns. Note that the missing values are included in these columns, so those will be cleaned out of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0110e2ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          name        date  \\\n",
      "0  NEWARK LIBERTY INTERNATIONAL AIRPORT, NJ US  2016-01-01   \n",
      "1  NEWARK LIBERTY INTERNATIONAL AIRPORT, NJ US  2016-01-02   \n",
      "2  NEWARK LIBERTY INTERNATIONAL AIRPORT, NJ US  2016-01-03   \n",
      "3  NEWARK LIBERTY INTERNATIONAL AIRPORT, NJ US  2016-01-04   \n",
      "4  NEWARK LIBERTY INTERNATIONAL AIRPORT, NJ US  2016-01-05   \n",
      "\n",
      "   avg_daily_wind_mph  precip_in  snow_accum_in  snow_depth_in  avg_temp_f  \\\n",
      "0               12.75        0.0            0.0            0.0          41   \n",
      "1                9.40        0.0            0.0            0.0          36   \n",
      "2               10.29        0.0            0.0            0.0          37   \n",
      "3               17.22        0.0            0.0            0.0          32   \n",
      "4                9.84        0.0            0.0            0.0          19   \n",
      "\n",
      "   max_temp_f  min_temp_f  \n",
      "0          43          34  \n",
      "1          42          30  \n",
      "2          47          28  \n",
      "3          35          14  \n",
      "4          31          10  \n"
     ]
    }
   ],
   "source": [
    "newark = newark.drop(['station', 'avg_2sec_wind_dir', 'avg_5sec_wind_dir', 'max_2sec_wind_mph', 'max_5sec_wind_mph'], axis=1)\n",
    "print(newark.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d8ff69",
   "metadata": {},
   "source": [
    "10. Now, let's *describe* **newark** to see if we can see any oddities or potential outliers in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f1a3588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       avg_daily_wind_mph   precip_in  snow_accum_in  snow_depth_in  \\\n",
      "count          366.000000  366.000000     366.000000     366.000000   \n",
      "mean             9.429973    0.104945       0.098087       0.342623   \n",
      "std              3.748174    0.307496       1.276498       2.078510   \n",
      "min              2.460000    0.000000       0.000000       0.000000   \n",
      "25%              6.765000    0.000000       0.000000       0.000000   \n",
      "50%              8.720000    0.000000       0.000000       0.000000   \n",
      "75%             11.410000    0.030000       0.000000       0.000000   \n",
      "max             22.820000    2.790000      24.000000      20.100000   \n",
      "\n",
      "       avg_temp_f  max_temp_f  min_temp_f  \n",
      "count  366.000000  366.000000  366.000000  \n",
      "mean    57.196721   65.991803   48.459016  \n",
      "std     17.466981   18.606301   17.135790  \n",
      "min      8.000000   18.000000    0.000000  \n",
      "25%     43.000000   51.250000   35.000000  \n",
      "50%     56.000000   66.000000   47.000000  \n",
      "75%     74.000000   83.000000   64.000000  \n",
      "max     89.000000   99.000000   80.000000  \n"
     ]
    }
   ],
   "source": [
    "print(newark.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1260f9ed",
   "metadata": {},
   "source": [
    "Let's print the data types of each column to see if the data matches the expected data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f673c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name                   object\n",
      "date                   object\n",
      "avg_daily_wind_mph    float64\n",
      "precip_in             float64\n",
      "snow_accum_in         float64\n",
      "snow_depth_in         float64\n",
      "avg_temp_f              int64\n",
      "max_temp_f              int64\n",
      "min_temp_f              int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(newark.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0998733",
   "metadata": {},
   "source": [
    "Now let's write this to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "153a0fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "newark.to_csv('newark_wx.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
